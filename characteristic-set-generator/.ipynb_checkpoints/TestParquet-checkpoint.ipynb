{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1a9939-3a72-4359-8f89-6a66686837c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/13 13:23:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#cr√©er une session dans le master\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://172.20.53.96:7077\") \\\n",
    "    .appName(\"WDC-CSET+domains+sample\") \\\n",
    "    .config(\"spark.executor.memory\",\"28g\") \\\n",
    "    .config(\"spark.driver.memory\",\"28g\") \\\n",
    "    .getOrCreate()\n",
    "#spark = SparkSession.builder.master(\"local\").appName(\"WDC-CSET+domains+sample\").getOrCreate()\n",
    "spark.conf.set(\"spark.worker.cleanup.enabled\",True)\n",
    "spark.conf.set(\"spark.worker.cleanup.interval\",1800)\n",
    "spark.conf.set(\"spark.worker.cleanup.appDataTtl\",3600)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",1000)\n",
    "\n",
    "#fichiers de config qui permettent de se connecter au serveur de stockage s3 qui contient les fichiers de DataCommons\n",
    "endpoint_url = 'https://s3.os-bird.glicid.fr/'\n",
    "aws_access_key_id = '***REMOVED***'\n",
    "aws_secret_access_key = '***REMOVED***'\n",
    "hadoopConf = spark._jsc.hadoopConfiguration()\n",
    "hadoopConf.set('fs.s3a.access.key', aws_access_key_id)\n",
    "hadoopConf.set('fs.s3a.secret.key', aws_secret_access_key)\n",
    "hadoopConf.set('fs.s3a.endpoint', endpoint_url)\n",
    "hadoopConf.set('fs.s3a.path.style.access', 'true')\n",
    "hadoopConf.set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "\n",
    "hadoopConf.set('spark.worker.cleanup.enabled', 'true')\n",
    "hadoopConf.set('fs.s3a.committer.name', 'magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604f91fc-36e8-4aad-a681-f05b647cadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/13 13:23:50 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------------------+\n",
      "|                pset|count|              sample|distinct_domains_count|\n",
      "+--------------------+-----+--------------------+----------------------+\n",
      "|<schema.org/descr...|   97|https://www.gotah...|                     4|\n",
      "|<schema.org/conta...|    3|https://www.leadc...|                     3|\n",
      "|<schema.org/addre...| 2683|http://chelyabins...|                    40|\n",
      "|<schema.org/autho...|    5|http://rodrigo-si...|                     3|\n",
      "|isa:<welcome.vara...|    1|https://welcome.v...|                     1|\n",
      "|<schema.org/agent...|   63|https://www.delaw...|                     1|\n",
      "|<schema.org/autho...|  697|https://mgronline...|                    13|\n",
      "|<schema.org/autho...|   44|https://dinnerton...|                     2|\n",
      "|isa:<welcome.vara...|    3|https://welcome.v...|                     1|\n",
      "|<schema.org/addit...|    1|https://myphamhuy...|                     1|\n",
      "|<schema.org/descr...|    2|https://groupes.l...|                     1|\n",
      "|isa:<welcome.vara...|    3|https://welcome.v...|                     1|\n",
      "|<schema.org/addit...|   33|https://oldskippe...|                     4|\n",
      "|<schema.org/autho...|   44|https://www.where...|                     1|\n",
      "|<schema.org/alumn...|    7|https://suckhoeva...|                     1|\n",
      "|<schema.org/avail...|   61|https://pracovneo...|                     1|\n",
      "|isa:<varagesale.c...|    1|https://www.varag...|                     1|\n",
      "|<schema.org/descr...|    1|https://www.accom...|                     1|\n",
      "|<schema.org/addre...|  134|https://www.dezme...|                     1|\n",
      "|<schema.org/descr...|    1|https://www.accom...|                     1|\n",
      "+--------------------+-----+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 's3a://ter-2024/ddomain-240209/hashdom6-20/part-00975-2145dc48-c2f0-4de4-8c33-8b1231e3e36a-c000.gz.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#df = spark.read.parquet('s3a://ter-2024/ddomain-240209/hashdom6-20/')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#df.printSchema()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 10\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3a://ter-2024/ddomain-240209/hashdom6-20/part-00975-2145dc48-c2f0-4de4-8c33-8b1231e3e36a-c000.gz.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLa taille du fichier est: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m octets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre de lignes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcount())\n",
      "File \u001b[0;32m/webdatacommons_data/miniconda3/envs/jupyter/lib/python3.10/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 's3a://ter-2024/ddomain-240209/hashdom6-20/part-00975-2145dc48-c2f0-4de4-8c33-8b1231e3e36a-c000.gz.parquet'"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('s3a://ter-2024/ddomain-240209/hashdom6-20/part-00975-2145dc48-c2f0-4de4-8c33-8b1231e3e36a-c000.gz.parquet')\n",
    "\n",
    "#df = spark.read.parquet('s3a://ter-2024/ddomain-240209/hashdom6-20/')\n",
    "\n",
    "#df.printSchema()\n",
    "\n",
    "df.show()\n",
    "\n",
    "print(\"Nombre de lignes:\", df.count())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
