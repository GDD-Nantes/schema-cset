{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1a9939-3a72-4359-8f89-6a66686837c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/13 13:49:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#cr√©er une session dans le master\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://172.20.53.96:7077\") \\\n",
    "    .appName(\"WDC-CSET+domains+sample\") \\\n",
    "    .config(\"spark.executor.memory\",\"28g\") \\\n",
    "    .config(\"spark.driver.memory\",\"28g\") \\\n",
    "    .getOrCreate()\n",
    "#spark = SparkSession.builder.master(\"local\").appName(\"WDC-CSET+domains+sample\").getOrCreate()\n",
    "spark.conf.set(\"spark.worker.cleanup.enabled\",True)\n",
    "spark.conf.set(\"spark.worker.cleanup.interval\",1800)\n",
    "spark.conf.set(\"spark.worker.cleanup.appDataTtl\",3600)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",1000)\n",
    "\n",
    "#fichiers de config qui permettent de se connecter au serveur de stockage s3 qui contient les fichiers de DataCommons\n",
    "endpoint_url = 'https://s3.os-bird.glicid.fr/'\n",
    "aws_access_key_id = 'bbd95ea3c1174caa88345404b84e458f'\n",
    "aws_secret_access_key = 'eaf2a72ecf9845f583af7f3513c44f25'\n",
    "hadoopConf = spark._jsc.hadoopConfiguration()\n",
    "hadoopConf.set('fs.s3a.access.key', aws_access_key_id)\n",
    "hadoopConf.set('fs.s3a.secret.key', aws_secret_access_key)\n",
    "hadoopConf.set('fs.s3a.endpoint', endpoint_url)\n",
    "hadoopConf.set('fs.s3a.path.style.access', 'true')\n",
    "hadoopConf.set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "\n",
    "hadoopConf.set('spark.worker.cleanup.enabled', 'true')\n",
    "hadoopConf.set('fs.s3a.committer.name', 'magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604f91fc-36e8-4aad-a681-f05b647cadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/13 13:49:22 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------------------+\n",
      "|                pset|count|              sample|distinct_domains_count|\n",
      "+--------------------+-----+--------------------+----------------------+\n",
      "|<schema.org/descr...|   97|https://www.gotah...|                     4|\n",
      "|<schema.org/conta...|    3|https://www.leadc...|                     3|\n",
      "|<schema.org/addre...| 2683|http://chelyabins...|                    40|\n",
      "|<schema.org/autho...|    5|http://rodrigo-si...|                     3|\n",
      "|isa:<welcome.vara...|    1|https://welcome.v...|                     1|\n",
      "|<schema.org/agent...|   63|https://www.delaw...|                     1|\n",
      "|<schema.org/autho...|  697|https://mgronline...|                    13|\n",
      "|<schema.org/autho...|   44|https://dinnerton...|                     2|\n",
      "|isa:<welcome.vara...|    3|https://welcome.v...|                     1|\n",
      "|<schema.org/addit...|    1|https://myphamhuy...|                     1|\n",
      "|<schema.org/descr...|    2|https://groupes.l...|                     1|\n",
      "|isa:<welcome.vara...|    3|https://welcome.v...|                     1|\n",
      "|<schema.org/addit...|   33|https://oldskippe...|                     4|\n",
      "|<schema.org/autho...|   44|https://www.where...|                     1|\n",
      "|<schema.org/alumn...|    7|https://suckhoeva...|                     1|\n",
      "|<schema.org/avail...|   61|https://pracovneo...|                     1|\n",
      "|isa:<varagesale.c...|    1|https://www.varag...|                     1|\n",
      "|<schema.org/descr...|    1|https://www.accom...|                     1|\n",
      "|<schema.org/addre...|  134|https://www.dezme...|                     1|\n",
      "|<schema.org/descr...|    1|https://www.accom...|                     1|\n",
      "+--------------------+-----+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('s3a://ter-2024/ddomain-240209/hashdom6-20/part-00975-2145dc48-c2f0-4de4-8c33-8b1231e3e36a-c000.gz.parquet')\n",
    "\n",
    "#df = spark.read.parquet('s3a://ter-2024/ddomain-240209/hashdom6-20/')\n",
    "\n",
    "#df.printSchema()\n",
    "\n",
    "df.show()\n",
    "\n",
    "print(\"Nombre de lignes:\", df.count())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
