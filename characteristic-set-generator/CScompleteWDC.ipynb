{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ece345-0a23-40bc-898d-17686ef4e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#créer une session dans le master\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://172.20.53.96:7077\") \\\n",
    "    .appName(\"WDC-complete\") \\\n",
    "    .config(\"spark.executor.memory\",\"20g\") \\\n",
    "    .config(\"spark.driver.memory\",\"20g\") \\\n",
    "    .getOrCreate()\n",
    "#spark = SparkSession.builder.master(\"local\").appName(\"WDC-complete\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",1000)\n",
    "\n",
    "#fichiers de config qui permettent de se connecter au serveur de stockage s3 qui contient les fichiers de DataCommons\n",
    "endpoint_url = 'https://s3.os-bird.glicid.fr/'\n",
    "aws_access_key_id = '***REMOVED***'\n",
    "aws_secret_access_key = '***REMOVED***'\n",
    "hadoopConf = spark._jsc.hadoopConfiguration()\n",
    "hadoopConf.set('fs.s3a.access.key', aws_access_key_id)\n",
    "hadoopConf.set('fs.s3a.secret.key', aws_secret_access_key)\n",
    "hadoopConf.set('fs.s3a.endpoint', endpoint_url)\n",
    "hadoopConf.set('fs.s3a.path.style.access', 'true')\n",
    "hadoopConf.set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "\n",
    "hadoopConf.set('spark.worker.cleanup.enabled', 'true')\n",
    "hadoopConf.set('fs.s3a.committer.name', 'magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9c2a7-d574-4cd2-adcb-9c193dcd5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from pyspark.sql import Row\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "line='_:nb53a24408607424384c1357880ce1bc7xb1 <http://schema.org/value> \"8,840 ft / 2,694 m\" <https://peakery.com/dragontail-peak-washington/>   .'\n",
    "quad_motif=re.compile(r'(.+)\\s(<.+>)\\s(.+)<(.+)>\\s+.')\n",
    "\n",
    "def parseQ(l):\n",
    "  result=quad_motif.match(l)\n",
    "  #print(result.groups())\n",
    "  pred=result.group(2)\n",
    "  if result.group(2)==\"<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>\":\n",
    "      pred=\"isa:\"+result.group(3)\n",
    "  domain=urlparse(result.group(4)).netloc\n",
    "  return Row(subject=result.group(1),predicate=pred,prov=domain,hashdom=hash(domain)%10)\n",
    "\n",
    "print(parseQ(line))\n",
    "\n",
    "#lines = spark.sparkContext.textFile(\"s3a://test/\")\n",
    "lines = spark.sparkContext.textFile(\"s3a://wdc/\")\n",
    "\n",
    "sp=lines.map(lambda l: parseQ(l)).toDF()\n",
    "\n",
    "# permet de ne plus différencier les predicats http, https, www...\n",
    "sp = sp.withColumn(\"predicate\", f.regexp_replace(f.col(\"predicate\"), \"([Hh][Tt][Tt][Pp][Ss]?://)?([Ww]{3}\\.)?\", \"\"))\n",
    "sp.show(truncate=0)\n",
    "\n",
    "sp.createOrReplaceTempView(\"Super\")\n",
    "#spark.sql(\"select count(*) as count from Super\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2045253-103e-40d7-b52d-30314c56bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    hashdom_val = i\n",
    "    file_name = f\"hashdom{hashdom_val+1}-10\"\n",
    "    cset2 = spark.sql(f\"select subject, concat_ws('|',sort_array(collect_set(predicate))) as pset FROM Super where hashdom={hashdom_val} group by  subject \").cache()\n",
    "    cset2.show(truncate=200)\n",
    "    print(cset2.count())\n",
    "\n",
    "    result2 = cset2.groupby(\"pset\").agg(f.count(cset2.subject).alias('count'))\n",
    "    result2.show(truncate=0)\n",
    "\n",
    "    result2.write.option(\"header\",True) \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .csv(f\"s3a://test-out/wdc/{file_name}\")\n",
    "    \n",
    "    # clear variables from memory\n",
    "    cset2.unpersist()\n",
    "    result2.unpersist()\n",
    "    del cset2, result2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
